{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Use a Stacked Ensemble to predict Titanic passenger survival  \n",
    "\n",
    "This notebook contains steps and code to demonstrate how to build a Stacked Ensemble with scikit-learn. The model will address the Titanic passenger survival dataset available at [Kaggle](https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/a02e7cd6-8137-4390-891a-ed0d703ce30a?projectid=95cd1d8d-3ffc-4eea-906b-590efd3bf1fe&projectTitle=Instant%20Competition&context=cpdaas) \n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.7 and was tested in Watson Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "-  Import data\n",
    "-  Train and test Level 1 models\n",
    "-  Train and test a simple Stacked Ensemble\n",
    "-  Train and test a K Fold Stacked Ensemble\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Setup](#setup)\n",
    "2.\t[Train and test Level 1 models](#train)\n",
    "3.\t[Train and test a simple Stacked Ensemble](#simple)\n",
    "4.\t[Train and test a K Fold Stacked Ensemble](#kfold)\n",
    "5.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup \n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "- Download the Titanic dataset. Note that the following feature engineering modifications have been made to the dataset available from [Kaggle](https://www.kaggle.com/c/titanic/data)\n",
    "   - Extracted title from `Name`\n",
    "   - Imputed missing values for rows with missing `Age, Embarked and Fare`\n",
    "   - Mapped  titles to a fixed set\n",
    "   - Use `AgeGroup` instead of `Age`\n",
    "   - Added column `HadCabin` to indicate whether a passenger had an assigned Cabin or not \n",
    "   - Removed columns: `Cabin, Name, Age, PassengerId, Pclass `\n",
    "   \n",
    "- Import required packages\n",
    "\n",
    "- Split data into test and training sets   \n",
    " \n",
    "### 1.1 Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download data\n",
    "In order to save time we've applied the modifications noted above to the orginal dataset in order to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cp4d-workshop-datasets.s3.us-south.cloud-object-storage.appdomain.cloud/titanic_train_cleaned_v2.csv  --output-document=titanic_train_cleaned_v2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Split data into test and training sets\n",
    "\n",
    "Kaggle does provide a training and test set for the competitition but the test set is unlabeled. So we'll work with just the training set.\n",
    "\n",
    "We use 2 splits:\n",
    "1. Split the original training set into training and test data\n",
    "2. Split the new training set in half for the implementation of a simple Stacked Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('titanic_train_cleaned_v2.csv')\n",
    "\n",
    "X = df_data.drop(columns=['Survived'])\n",
    "y = df_data['Survived']\n",
    "\n",
    "# First split on entire training set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80,test_size=0.20, random_state=100)\n",
    "\n",
    "# Second split to be used for simple Stacked Ensemble\n",
    "X_train_first_half, X_train_second_half, y_train_first_half, y_train_second_half = train_test_split(X_train, y_train, train_size=0.50,test_size=0.50, random_state=100)\n",
    "\n",
    "# Set up ColumnTransformer to scale columns . i.e. subtract the mean from each value and scale to unit variance\n",
    "cols_to_scale = ['Fare']\n",
    "scaler = StandardScaler()\n",
    "preprocessor = ColumnTransformer(transformers = [('scaler', scaler, cols_to_scale)], remainder ='passthrough')\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create Dataframes for the Simple Stacked Ensemble \n",
    "\n",
    "We'll build the simple Ensemble from scratch . We need the predictions from the Level 1 models to serve as input. These dataframes will be used to store those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the meta model\n",
    "df_simple_stacked_ensemble_train = pd.DataFrame()\n",
    "\n",
    "# For testing the meta model \n",
    "df_simple_stacked_ensemble_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## 2. Train and test Level 1 models\n",
    "\n",
    "In this section, you will train and test the  Level 1 models. You will be using 2 Level 1 models:\n",
    "\n",
    "1. Gradient Boosting\n",
    "\n",
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Gradient Boosting Level 1 model\n",
    "\n",
    "Train the model on the first half of the training data and generate the predictions for the second half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and pipeline \n",
    "gb_classifier = GradientBoostingClassifier(random_state=1)\n",
    "gb_pipeline = Pipeline([('preprocessor', preprocessor), ('gb', gb_classifier )])\n",
    "\n",
    "# Train model on first half of training data\n",
    "gb_model = gb_pipeline.fit(X_train_first_half, y_train_first_half)\n",
    "\n",
    "# Generate probabilities for second half \n",
    "y_train_proba = gb_model.predict_proba(X_train_second_half)[:,1]\n",
    "df_simple_stacked_ensemble_train['gb'] = y_train_proba.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain on all training data and generate probabilities to test the simple Stacked Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model on all training data\n",
    "gb_model = gb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Generate probabilities for test data\n",
    "y_test_proba = gb_model.predict_proba(X_test)[:,1]\n",
    "df_simple_stacked_ensemble_test['gb'] = y_test_proba.tolist()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model by itself to compare later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb_model.predict(X_test)\n",
    "gb_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print('%s %.3f ' % ('Gradient Boosting accuracy is ', gb_accuracy_score))\n",
    "print('Confusion Matrix')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "accuracy_scores, model_names = list(), list()\n",
    "accuracy_scores.append(gb_accuracy_score)\n",
    "model_names.append('Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest Level 1 model\n",
    "\n",
    "Train the model on the first half of the training data and generate the predictions for the second half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and pipeline \n",
    "rf_classifier = RandomForestClassifier(random_state=1)\n",
    "rf_pipeline = Pipeline([('preprocessor', preprocessor), ('rf', rf_classifier )])\n",
    "\n",
    "# Train model on first half of training data\n",
    "rf_model = rf_pipeline.fit(X_train_first_half, y_train_first_half)\n",
    "\n",
    "# Generate probabilities  for second half \n",
    "y_train_proba = rf_model.predict_proba(X_train_second_half)[:,1]\n",
    "df_simple_stacked_ensemble_train['rf'] = y_train_proba.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain on all training data and generate probabilities to test the simple Stacked Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model on all training data\n",
    "rf_model = rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Generate probabilities for test data\n",
    "y_test_proba = rf_model.predict_proba(X_test)[:,1]\n",
    "df_simple_stacked_ensemble_test['rf'] = y_test_proba.tolist()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model by itself to compare later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "rf_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print('%s %.3f ' % ('Random Forest accuracy is ', rf_accuracy_score))\n",
    "print('Confusion Matrix')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "accuracy_scores.append(rf_accuracy_score)\n",
    "model_names.append('Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"simple\"></a>\n",
    "## 3. Simple Stacked Ensemble\n",
    "\n",
    "This meta model is trained using the prediction probablities from the Level 1 models. We will use  Logistic Regression  for our meta model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training probabilities generated by Level 1 models. Should see a column for each Level 1 model. \n",
    "df_simple_stacked_ensemble_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check testing probabilities generated by Level 1 models. Should see a column for each Level 1 model. \n",
    "df_simple_stacked_ensemble_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta model\n",
    "ensemble1_meta_model = LogisticRegression()\n",
    "\n",
    "# Train model using prediction probabilities of Level 1 models\n",
    "ensemble1_model = ensemble1_meta_model.fit(df_simple_stacked_ensemble_train, y_train_second_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate meta model using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensemble1_model.predict(df_simple_stacked_ensemble_test)\n",
    "ensemble1_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print('%s %.3f ' % ('Ensemble Simple Split accuracy is ', ensemble1_accuracy_score))\n",
    "print('Confusion Matrix')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "accuracy_scores.append(ensemble1_accuracy_score)\n",
    "model_names.append('Simple Stacked Ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kfold\"></a>\n",
    "## 4. K fold Stacked Ensemble\n",
    "\n",
    "This meta model is trained using the prediction probabilities from the Level 1 models. We will use  Logistic Regression  for our meta model.  We will use the scikit-learn class `StackingClassifier` to build this.\n",
    "\n",
    "Build and train the StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (untrained) Level 1 models\n",
    "ensemble2_level1_models = list()\n",
    "ensemble2_level1_models.append(('Gradient Boosting', GradientBoostingClassifier(random_state=1)))\n",
    "ensemble2_level1_models.append(('Random Forest', RandomForestClassifier(random_state=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta model\n",
    "ensemble2_meta_model = LogisticRegression()\n",
    "\n",
    "# Setup K fold (we'll use 10 folds)\n",
    "ensemble2_cross_validation = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StackingClassifier and pipeline\n",
    "ensemble2 = StackingClassifier(estimators=ensemble2_level1_models, stack_method='predict_proba', final_estimator=ensemble2_meta_model, cv=ensemble2_cross_validation)\n",
    "ensemble2_pipeline = Pipeline([('preprocessor', preprocessor), ('ensemble', ensemble2)])\n",
    "\n",
    "# Train \n",
    "ensemble2_model = ensemble2_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate meta model using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensemble2_model.predict(X_test)\n",
    "ensemble2_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print('%s %.3f ' % ('Ensemble K Fold accuracy is ', ensemble2_accuracy_score))\n",
    "print('Confusion Matrix')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "accuracy_scores.append(ensemble2_accuracy_score)\n",
    "model_names.append('K fold Stacked Ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 5. Summary\n",
    "\n",
    "Lets visualize the results to compare them and wrap things up\n",
    "\n",
    "### 5.1 Utilities to help with drawing chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sort 2 lists based on the sort order of the first list\n",
    "def sort_lists(list1, list2):\n",
    "   zipped_lists = zip(list1, list2)\n",
    "   sorted_pairs = sorted(zipped_lists)\n",
    "\n",
    "   tuples = zip(*sorted_pairs)\n",
    "   list1, list2 = [ list(tuple) for tuple in  tuples]\n",
    "\n",
    "   return list1, list2\n",
    "\n",
    "# Adds y value on top of bar in bar chart\n",
    "# Source: http://composition.al/blog/2015/11/29/a-better-way-to-add-labels-to-bar-charts-with-matplotlib/\n",
    "def autolabel(rects, ax):\n",
    "    # Get y-axis height to calculate label position from.\n",
    "    (y_bottom, y_top) = ax.get_ylim()\n",
    "    y_height = y_top - y_bottom\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        label_position = height + (y_height * 0.01)\n",
    "\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., label_position,\n",
    "                '%.3f' % float(height),\n",
    "                ha='center', va='bottom')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Draw chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_accuracy_scores, sorted_model_names = sort_lists(accuracy_scores, model_names)\n",
    "acc_series = pd.Series(sorted_accuracy_scores)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects = ax.bar(sorted_model_names, sorted_accuracy_scores, color='green')\n",
    "ax.set_title('Accuracy listed by model')\n",
    "ax.set_xlabel('Model type')\n",
    "ax.set_ylabel('Accuracy on test data')\n",
    "ax.set_xticklabels(sorted_model_names, rotation=45)\n",
    "ax.axes.yaxis.set_visible(False)\n",
    "ax.set_yscale('log')\n",
    "bar_labels = [\"%.2f\" % i for i in sorted_accuracy_scores]\n",
    "\n",
    "autolabel(rects, ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Wrap up\n",
    "\n",
    "Congrats ! You've successfully built two  Stacked Ensemble models !\n",
    "\n",
    "If you would like to keep working on this dataset we suggest you try your hand at improving this and enter it in the ongoing  [Kaggle Competition](https://www.kaggle.com/c/titanic).\n",
    "\n",
    "**Note**: To generate a Kaggle entry you will need to download the Kaggle test datset (it's unlabelled) and generate an entry. Here's an example:\n",
    "\n",
    "```\n",
    "\n",
    "# Read in Kaggle test data set\n",
    "df_test =  pd.read_csv('test.csv')\n",
    "\n",
    "# Remove PassengerId before using test data and   modify/enhance as needed\n",
    "X_test = df_test.drop(columns=['PassengerId'])\n",
    "...\n",
    "\n",
    "\n",
    "# Code to build your ensemble model goes here\n",
    "... \n",
    "\n",
    "# Generate predictions\n",
    "y_pred = ensemble.predict(X_test_modified)\n",
    "\n",
    "# Create Kaggle entry file\n",
    "kaggle_entry = pd.DataFrame({'PassengerId': df_test['PassengerId'].values,'Survived': y_pred})\n",
    "kaggle_entry.to_csv('my_titanic_entry_v1.csv', index=False)\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
